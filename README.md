# An√°lisis Predictivo de Enfermedades Card√≠acas con Kotlin y Smile

Este proyecto tiene el objetivo principal de aplicar el ciclo completo de an√°lisis de datos utilizando un dataset real relacionado con enfermedades card√≠acas. Todo el desarrollo se realiz√≥ en **Kotlin**, con el uso de la biblioteca **Smile** para el modelo de clasificaci√≥n.

---

## Dataset Utilizado

* **Nombre**: Heart Disease UCI
* **Fuente**: Kaggle
* **Enlace**: [https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)
* **Tama√±o**: 918 registros
* **Columnas**: 12 variables cl√≠nicas + 1 columna objetivo (presencia de enfermedad card√≠aca)

Este dataset contiene informaci√≥n relevante como edad, colesterol, presi√≥n arterial, entre otras, para predecir si un paciente desarrollar√° una enfermedad card√≠aca.

---

## Herramientas y Tecnolog√≠as

* **Lenguaje**: Kotlin
* **Machine Learning**: Smile (Statistical Machine Intelligence and Learning Engine)
* **Interfaz**: CLI (Interfaz por consola)

---

## Flujo de Trabajo Implementado

### *1. Carga y Preprocesamiento del Dataset*

* Se carga el archivo `heart.csv` desde la carpeta `data/`.
* Se convierten variables categ√≥ricas en num√©ricas para poder entrenar el modelo:

  * `Sex`: M/F ‚Üí 1/0
  * `ChestPainType`: ATA/NAP/ASY/TA ‚Üí 0/1/2/3
  * `RestingECG`: Normal/ST/LVH ‚Üí 0/1/2
  * `ExerciseAngina`: Y/N ‚Üí 1/0
  * `ST_Slope`: Up/Flat/Down ‚Üí 0/1/2
* Se eliminan registros con valores no reconocidos (donde la conversi√≥n d√° -1).

### *2. Normalizaci√≥n de Datos*

* Se aplica normalizaci√≥n Min-Max sobre los atributos num√©ricos.
* Esto evita que variables con distintas magnitudes afecten negativamente el modelo.

### *3. Divisi√≥n del Dataset (Train/Test Split)*

* Se hace un split 80/20: 80% de los datos se usan para entrenamiento, 20% para pruebas.
* Los datos se barajan aleatoriamente para asegurar una representaci√≥n equilibrada.

### *4. Entrenamiento del Modelo*

* Se entrena un modelo de **Regresi√≥n Log√≠stica** usando Smile.
* Elegimos este modelo porque es sencillo, interpretable y efectivo para clasificaci√≥n binaria.

### *5. Evaluaci√≥n del Modelo*

* Se calculan las siguientes m√©tricas:

  * **Accuracy**: porcentaje total de aciertos
  * **Precision**: exactitud en los positivos predichos
  * **Recall**: proporci√≥n de positivos correctamente detectados
  * **F1 Score**: media arm√≥nica de precision y recall

Ejemplo de salida por consola:

```
Resultados del modelo
Precisi√≥n (Accuracy): 82,07 %
Precision: 78,95 %
Recall: 85,23 %
F1 Score: 81,97 %
```

---

## Interfaz CLI (por consola)

Para interactuar con la aplicaci√≥n, se dise√±√≥ una interfaz por consola con el siguiente men√∫:

```
Men√∫ Principal
1. Cargar y preprocesar datos
2. Dividir datos en entrenamiento y prueba
3. Entrenar modelo
4. Ver m√©tricas de desempe√±o
5. Salir
```

Este men√∫ permite al usuario ejecutar el flujo completo paso a paso. Cada opci√≥n est√° pensada para guiar al usuario sin necesidad de modificar el c√≥digo.

---

## Estructura del Proyecto

```
 project-root
 data
   ‚îî‚îÄ heart.csv
 src
   ‚îúÔ∏è Main.kt
   ‚îúÔ∏è Paciente.kt
   ‚îúÔ∏è Preprocesamiento.kt
   ‚îúÔ∏è Modelo.kt
   ‚îîÔ∏è Evaluacion.kt
README.md
```

---

##  Explicaci√≥n de Archivos Fuente

### `Main.kt`

Este es el archivo principal donde se controla todo el flujo del programa mediante un men√∫ interactivo por consola.
Cada opci√≥n llama a funciones espec√≠ficas que se encargan de las distintas fases del an√°lisis:

```kotlin
fun main() {
  // Declaraci√≥n de variables globales
  var pacientes: List<Paciente> = listOf()
  var pacientesLimpios: List<Paciente> = listOf()
  var modelo: LogisticRegression? = null
  var xTest: Array<DoubleArray> = arrayOf()
  var yTest: IntArray = intArrayOf()
  var predicciones: IntArray = intArrayOf()

  while (true) {
    println("Men√∫ Principal")
    println("1. Cargar y preprocesar datos")
    println("2. Dividir datos en entrenamiento y prueba")
    println("3. Entrenar modelo")
    println("4. Ver m√©tricas de desempe√±o")
    println("5. Salir")
    print("Seleccione una opci√≥n: ")

    when (readLine()?.toIntOrNull()) {
      1 -> { /* Carga del CSV y conversiones */ }
      2 -> { /* Normalizaci√≥n y split */ }
      3 -> { /* Entrenamiento del modelo */ }
      4 -> { /* M√©tricas y resultados */ }
      5 -> break
      else -> println("Opci√≥n inv√°lida.")
    }
  }
}
```

Este archivo act√∫a como "coordinador" del programa, llamando a funciones de los otros archivos.

## **¬øQu√© hace este archivo?**

Controla el ciclo completo de ejecuci√≥n:

1. **Carga del dataset**
2. **Preprocesamiento y limpieza**
3. **Divisi√≥n de los datos (entrenamiento y prueba)**
4. **Entrenamiento del modelo**
5. **Evaluaci√≥n del modelo con m√©tricas**
6. **Interacci√≥n con el usuario mediante men√∫ en consola**

---

## **Estructura del c√≥digo y su explicaci√≥n**

```kotlin
package org.app

import java.io.File
import smile.classification.LogisticRegression

fun main() {
    var pacientes: List<Paciente> = listOf()
    var pacientesLimpios: List<Paciente> = listOf()
    var modelo: LogisticRegression? = null
    var xTest: Array<DoubleArray> = arrayOf()
    var yTest: IntArray = intArrayOf()
    var predicciones: IntArray = intArrayOf()
```

* Se definen variables globales para almacenar:

  * Los pacientes cargados desde el CSV
  * Una versi√≥n limpia sin errores o valores desconocidos
  * El modelo entrenado (usando Smile)
  * Los datos de prueba (X e Y) y sus predicciones

---

### **Men√∫ principal**

```kotlin
    while (true) {
        println("Men√∫ Principal")
        println("1. Cargar datos")
        println("2. Entrenar modelo")
        println("3. Ver m√©tricas")
        println("4. Salir")
        print("Seleccione una opci√≥n: ")

        when (readLine()?.toIntOrNull()) {
```

* Muestra un men√∫ simple de opciones para que el usuario pueda elegir qu√© desea hacer.
* El `when` act√∫a como un `switch` para ejecutar el bloque correspondiente a cada opci√≥n.

---

### **Opcion 1: Cargar datos**

```kotlin
            1 -> {
                val file = File("data/heart.csv")
                val lines = file.readLines().drop(1)
                val lista = mutableListOf<Paciente>()
                for (line in lines) {
                    val partes = line.split(",")
```

* Se abre el archivo CSV.
* Se omite la primera l√≠nea (cabecera).
* Se itera sobre cada fila y se convierte en un objeto `Paciente`.

```kotlin
                    val paciente = Paciente(
                        age = partes[0].toInt(),
                        sex = if (partes[1] == "M") 1 else 0,
                        chestPain = when (partes[2]) {
                            "ATA" -> 0
                            "NAP" -> 1
                            "ASY" -> 2
                            "TA"  -> 3
                            else -> -1
                        },
                        restingBP = partes[3].toInt(),
                        cholesterol = partes[4].toInt(),
                        fastingBS = partes[5].toInt(),
                        restECG = when (partes[6]) {
                            "Normal" -> 0
                            "ST"     -> 1
                            "LVH"    -> 2
                            else -> -1
                        },
                        maxHR = partes[7].toInt(),
                        exerciseAngina = if (partes[8] == "Y") 1 else 0,
                        oldpeak = partes[9].toDouble(),
                        stSlope = when (partes[10]) {
                            "Up"   -> 0
                            "Flat" -> 1
                            "Down" -> 2
                            else -> -1
                        },
                        target = partes[11].toInt()
                    )
                    lista.add(paciente)
                }
```

* Se hace conversi√≥n manual de variables categ√≥ricas a num√©ricas.
* Se construyen objetos `Paciente` para cada fila v√°lida.

```kotlin
                pacientes = lista
                pacientesLimpios = pacientes.filter {
                    it.chestPain != -1 && it.restECG != -1 && it.stSlope != -1
                }

                println("Pacientes cargados: ${pacientes.size}")
                println("Pacientes v√°lidos: ${pacientesLimpios.size}")
            }
```

* Se filtran registros con errores (-1).
* Se informa al usuario sobre los registros cargados y v√°lidos.

---

### **Opcion 2: Entrenar modelo**

```kotlin
            2 -> {
                if (pacientesLimpios.isEmpty()) {
                    println("Primero debe cargar los datos.")
                    continue
                }
```

* Verifica que haya datos limpios cargados.

```kotlin
                val datos = pacientesLimpios.shuffled()
                val tama√±oEntrenamiento = (datos.size * 0.8).toInt()
                val entrenamiento = datos.take(tama√±oEntrenamiento)
                val prueba = datos.drop(tama√±oEntrenamiento)
```

* Divide aleatoriamente en 80% entrenamiento y 20% prueba.

```kotlin
                fun convertirAEntradaSmile(pacientes: List<Paciente>): Pair<Array<DoubleArray>, IntArray> {
                    val features = pacientes.map {
                        doubleArrayOf(
                            it.age.toDouble(),
                            it.sex.toDouble(),
                            it.chestPain.toDouble(),
                            it.restingBP.toDouble(),
                            it.cholesterol.toDouble(),
                            it.fastingBS.toDouble(),
                            it.restECG.toDouble(),
                            it.maxHR.toDouble(),
                            it.exerciseAngina.toDouble(),
                            it.oldpeak,
                            it.stSlope.toDouble()
                        )
                    }.toTypedArray()
                    val labels = pacientes.map { it.target }.toIntArray()
                    return Pair(features, labels)
                }
```

* Convierte la lista de objetos `Paciente` en arreglos para Smile: `Array<DoubleArray>` para los atributos y `IntArray` para los targets.

```kotlin
                val (xTrain, yTrain) = convertirAEntradaSmile(entrenamiento)
                val (xPrueba, yPrueba) = convertirAEntradaSmile(prueba)

                modelo = LogisticRegression.fit(xTrain, yTrain)
                xTest = xPrueba
                yTest = yPrueba
                predicciones = xTest.map { modelo.predict(it) }.toIntArray()

                println("Modelo entrenado correctamente.")
            }
```

* Se entrena un modelo de regresi√≥n log√≠stica.
* Se generan predicciones con los datos de prueba.

---

### **Opcion 3: Ver m√©tricas**

```kotlin
            3 -> {
                if (modelo == null || yTest.isEmpty() || predicciones.isEmpty()) {
                    println("Primero debe entrenar el modelo.")
                    continue
                }
```

* Verifica que se haya entrenado un modelo antes de evaluar.

```kotlin
                fun calcularAccuracy(yTrue: IntArray, yPred: IntArray): Double {
                    val correctos = yTrue.indices.count { yTrue[it] == yPred[it] }
                    return correctos.toDouble() / yTrue.size
                }
```

* Calcula el porcentaje de aciertos.

```kotlin
                fun calcularPrecision(yTrue: IntArray, yPred: IntArray): Double {
                    val tp = yTrue.indices.count { yPred[it] == 1 && yTrue[it] == 1 }
                    val fp = yTrue.indices.count { yPred[it] == 1 && yTrue[it] == 0 }
                    return if (tp + fp == 0) 0.0 else tp.toDouble() / (tp + fp)
                }
```

* Calcula la precisi√≥n (positivos verdaderos sobre predicciones positivas).

```kotlin
                fun calcularRecall(yTrue: IntArray, yPred: IntArray): Double {
                    val tp = yTrue.indices.count { yPred[it] == 1 && yTrue[it] == 1 }
                    val fn = yTrue.indices.count { yPred[it] == 0 && yTrue[it] == 1 }
                    return if (tp + fn == 0) 0.0 else tp.toDouble() / (tp + fn)
                }
```

* Calcula la sensibilidad o recall (positivos verdaderos sobre todos los reales).

```kotlin
                fun calcularF1(precision: Double, recall: Double): Double {
                    return if (precision + recall == 0.0) 0.0 else 2 * (precision * recall) / (precision + recall)
                }
```

* Calcula la m√©trica F1: media arm√≥nica entre precisi√≥n y recall.

```kotlin
                val accuracy = calcularAccuracy(yTest, predicciones)
                val precision = calcularPrecision(yTest, predicciones)
                val recall = calcularRecall(yTest, predicciones)
                val f1 = calcularF1(precision, recall)

                println("Resultados del modelo")
                println("Precisi√≥n (Accuracy): %.2f %%".format(accuracy * 100))
                println("Precision: %.2f %%".format(precision * 100))
                println("Recall: %.2f %%".format(recall * 100))
                println("F1 Score: %.2f %%".format(f1 * 100))
            }
```

* Se muestran los resultados en consola de forma legible para el usuario.

---

### **Opcion 4: Salir**

```kotlin
            4 -> {
                println("Saliendo del programa.")
                break
            }
            else -> println("Opci√≥n inv√°lida.")
        }
    }
}
```

* Cierra el ciclo infinito `while` y termina el programa.
* Cualquier otra entrada fuera de 1-4 es considerada inv√°lida.

---

### `Paciente.kt`

Define una clase `Paciente` con los atributos del dataset. Sirve como estructura para representar cada fila del archivo CSV de forma tipada.

```kotlin
data class Paciente(
  val age: Int,
  val sex: Int,
  val chestPain: Int,
  val restingBP: Int,
  val cholesterol: Int,
  val fastingBS: Int,
  val restECG: Int,
  val maxHR: Int,
  val exerciseAngina: Int,
  val oldpeak: Double,
  val stSlope: Int,
  val target: Int
)
```

### `Preprocesamiento.kt`

Incluye funciones para:

* Normalizar datos (Min-Max scaling)
* Dividir en conjunto de entrenamiento y prueba
* Convertir listas de `Paciente` en arrays de Smile (`Array<DoubleArray>` y `IntArray`)

### `Modelo.kt`

Contiene funciones para:

* Entrenar el modelo de regresi√≥n log√≠stica
* Realizar predicciones sobre datos nuevos

### `Evaluacion.kt`

Calcula las m√©tricas (accuracy, precision, recall, F1). Cada m√©trica est√° implementada a mano para entender su funcionamiento.

---

## Decisiones de Dise√±o y Justificaci√≥n

* **Modelo elegido**: Regresi√≥n Log√≠stica. Es un modelo f√°cil de interpretar y funciona bien para clasificaci√≥n binaria.
* **Preprocesamiento**: Se normalizaron los datos y se codificaron las variables categ√≥ricas. Esto mejora el rendimiento y compatibilidad del modelo.
* **Estructura modular**: Separamos la l√≥gica en varios archivos para mantener claridad.

---

## Posibles Mejoras Futuras

* A√±adir validaci√≥n cruzada para mayor robustez.
* Implementar m√°s modelos y comparar resultados (KNN, √°rboles de decisi√≥n, etc.).
* Crear una interfaz gr√°fica (GUI) con Kotlin y Jetpack Compose o TornadoFX.

---

## Requisitos del sistema

* JDK 17 o superior
* Kotlin 1.9+
* Smile library (ya incluida en el build)
* Editor recomendado: IntelliJ IDEA

---

## Referencias

* Dataset original: Kaggle ‚Üí [Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)
* Documentaci√≥n de Smile: [https://haifengl.github.io](https://haifengl.github.io)

# Explicacion de la salida del proyecto:

# 1. Cargar y Preprocesar Datos
Cuando eliges la opci√≥n 1. Cargar y preprocesar datos, el programa:

Lee el archivo heart.csv desde la carpeta data/.

Omite la primera fila, que corresponde a los nombres de las columnas.

Lee cada l√≠nea como un paciente y transforma los datos categ√≥ricos en valores num√©ricos (codificaci√≥n manual).

Filtra registros inv√°lidos, asegur√°ndose de que todas las variables est√©n correctamente codificadas.

# ¬øQu√© significa la salida?
```
yaml
Total de registros: 918, v√°lidos: 918
```
Esto te dice dos cosas: 

Total de registros: Se encontraron 918 filas en el archivo heart.csv, lo cual es correcto y coincide con el dataset original de Kaggle llamado Heart Failure Prediction Dataset:
üîó https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction

V√°lidos: 918: Significa que no hubo registros con datos err√≥neos o mal codificados, es decir:

Todas las columnas categ√≥ricas (Sex, ChestPainType, RestingECG, ST_Slope, etc.) se codificaron correctamente.

No hay valores nulos o no reconocidos.

Por tanto, todos los registros son utilizables para el modelo.

# ¬øQu√© preprocesamiento se hizo?
Estas son las transformaciones clave:

Columna original	Transformaci√≥n realizada
```
Sex	"M" ‚Üí 1, "F" ‚Üí 0
ChestPainType	"ATA" ‚Üí 0, "NAP" ‚Üí 1, "ASY" ‚Üí 2, "TA" ‚Üí 3
RestingECG	"Normal" ‚Üí 0, "ST" ‚Üí 1, "LVH" ‚Üí 2
ExerciseAngina	"Y" ‚Üí 1, "N" ‚Üí 0
ST_Slope	"Up" ‚Üí 0, "Flat" ‚Üí 1, "Down" ‚Üí 2
```
Adem√°s, se eliminan (filtran) pacientes con valores "-1" (que marcan codificaci√≥n inv√°lida). Pero en tu caso, ninguno de los 918 registros fue descartado, lo cual es excelente.

# 2. Divisi√≥n en Entrenamiento y Prueba (Train/Test Split)

# ¬øQu√© significa?
En aprendizaje autom√°tico, necesitamos evaluar qu√© tan bien generaliza un modelo. Para lograrlo, dividimos el dataset original en dos partes:

Conjunto	Uso principal
Entrenamiento	Usado para entrenar el modelo: es donde el algoritmo "aprende".
Prueba	Usado para evaluar el modelo con datos no vistos durante el entrenamiento.

# ¬øC√≥mo se divide?
En tu c√≥digo, al llamar a modeloML.entrenar(pacientesLimpios) se realiza internamente:

```
kotlin

val tama√±oEntrenamiento = (datos.size * 0.8).toInt()
val entrenamiento = datos.take(tama√±oEntrenamiento)
val prueba = datos.drop(tama√±oEntrenamiento)
```
Eso quiere decir:

Se toma el 80% de los pacientes (aproximadamente 734 pacientes) para entrenamiento.

El 20% restante (aproximadamente 184 pacientes) se reserva como conjunto de prueba.

Este tipo de divisi√≥n es est√°ndar y permite medir si el modelo est√° sobreajustado o si realmente generaliza bien.

# ¬øQu√© significa el mensaje de salida?
```nginx
Los datos ya est√°n listos para ser usados.
```
Esto no est√° haciendo una divisi√≥n real en ese momento, sino que simplemente confirma que los datos est√°n limpios y listos para usar. La divisi√≥n en s√≠ ocurre en el paso 3 (cuando entrenas el modelo). El mensaje puede parecer un poco confuso porque no se hace una acci√≥n directa aqu√≠, pero sirve para asegurarte de que ya tienes datos v√°lidos en memoria.

# 3. ¬øQu√© significa ‚Äúentrenar el modelo‚Äù?
Entrenar un modelo significa que el algoritmo de aprendizaje autom√°tico (en tu caso, la regresi√≥n log√≠stica) analiza los datos de entrenamiento (80% del total) para aprender patrones que permitan predecir si un nuevo paciente tiene o no enfermedad card√≠aca.

Concretamente:

Usa los datos de entrada (xTrain) y las etiquetas reales (yTrain) para ajustar los coeficientes del modelo.

Despu√©s de entrenarse, el modelo puede hacer predicciones sobre datos no vistos, como el conjunto de prueba o pacientes ingresados manualmente.

# Resultado final
Despu√©s del mensaje de SLF4J, el programa imprime:

```
nginx
Modelo entrenado correctamente.
```
Eso significa que:

El modelo fue ajustado con √©xito usando los datos.

Est√° listo para hacer predicciones y para que se eval√∫en sus m√©tricas.

¬øQu√© son las m√©tricas de desempe√±o?
Las m√©tricas de desempe√±o sirven para medir la calidad del modelo al hacer predicciones. Se calculan comparando:

Las predicciones del modelo (yPred).

Los resultados reales del conjunto de prueba (yReal).

Estas m√©tricas indican qu√© tan preciso, confiable y √∫til es el modelo para diagnosticar enfermedades card√≠acas.

# An√°lisis de tus m√©tricas:
matlab
Copiar
Editar
M√âTRICAS DEL MODELO
Accuracy : 84,24 %
Precisi√≥n: 83,81 %
Recall   : 88,00 %
F1 Score : 85,85 %
Veamos cada una:

# Accuracy (Exactitud): 84,24 %
Indica cu√°ntas predicciones totales fueron correctas (positivas o negativas).

En tu caso, el modelo acierta el 84% de las veces en general.

F√≥rmula:

Accuracy
=
ùëá
ùëÉ
+
ùëá
ùëÅ
ùëá
ùëú
ùë°
ùëé
ùëô
Accuracy= 
Total
TP+TN
‚Äã
 
# Precisi√≥n (Precision): 83,81 %
Mide cu√°ntos de los casos predichos como positivos realmente lo eran.

Importa cuando queremos minimizar falsos positivos (diagnosticar enfermedad cuando no la hay).

En medicina, esto es clave para no alarmar a pacientes sanos.

# Recall (Sensibilidad): 88,00 %
Mide cu√°ntos de los pacientes que realmente tienen la enfermedad fueron detectados por el modelo.

Importa mucho cuando no queremos que se escape ning√∫n enfermo (minimizar falsos negativos).

# F1 Score: 85,85 %
Es el promedio arm√≥nico entre precisi√≥n y recall.

Sirve como medida equilibrada si te importan tanto los falsos positivos como los falsos negativos.

Cuanto m√°s alto, mejor balance entre ambos.

# Interpretaci√≥n m√©dica del modelo
El modelo:

Detecta bien a los enfermos (88% recall).

Comete pocos errores en positivos falsos (84% precisi√≥n).

Tiene una exactitud general alta (84%).

Es un modelo bien equilibrado y bastante fiable para diagn√≥stico preliminar.

# Campos de ingresar para la predicci√≥n manual
Cuando ejecutas la opci√≥n 5, el programa te pide los siguientes datos:

# 1. Edad (age)
Tipo: Entero (por ejemplo, 45)

Qu√© es: Edad del paciente en a√±os.

Por qu√© importa: A mayor edad, mayor riesgo de enfermedad card√≠aca.

# 2. Sexo (sex)
Tipo: 1 para Hombre, 0 para Mujer

Qu√© es: Sexo biol√≥gico del paciente.

Por qu√© importa: Los hombres tienen un riesgo mayor de enfermedad card√≠aca a edades m√°s tempranas.

# 3. Tipo de dolor en el pecho (chestPain)
Valores posibles:

0 = Angina t√≠pica (ATA)

1 = Angina at√≠pica (NAP)

2 = Dolor no anginoso (ASY)

3 = Dolor tipo TA (probablemente m√°s grave)

Qu√© es: Tipo de dolor que experimenta el paciente.

Por qu√© importa: Algunos tipos de dolor est√°n m√°s relacionados con enfermedad card√≠aca.

# 4. Presi√≥n arterial en reposo (restingBP)
Tipo: Entero (por ejemplo, 120)

Qu√© es: Presi√≥n arterial en mil√≠metros de mercurio cuando el paciente est√° en reposo.

Por qu√© importa: La hipertensi√≥n es un factor de riesgo.

# 5. Colesterol (cholesterol)
Tipo: Entero (por ejemplo, 240)

Qu√© es: Nivel de colesterol en sangre (mg/dL).

Por qu√© importa: El colesterol alto contribuye a la obstrucci√≥n de arterias.

# 6. FastingBS (nivel de az√∫car en ayunas)
Tipo: 1 si el nivel de glucosa en ayunas es > 120 mg/dL, 0 en caso contrario.

Qu√© es: Glucosa en sangre sin haber comido.

Por qu√© importa: Altos niveles indican diabetes, que aumenta el riesgo card√≠aco.

# 7. RestECG (electrocardiograma en reposo)
Valores:

0 = Normal

1 = Anormalidad en ST-T

2 = Hipertrofia ventricular izquierda (LVH)

Qu√© es: Resultado del electrocardiograma mientras el paciente est√° en reposo.

Por qu√© importa: Puede mostrar se√±ales de problemas card√≠acos.

# 8. Frecuencia card√≠aca m√°xima (maxHR)
Tipo: Entero (por ejemplo, 160)

Qu√© es: Ritmo m√°ximo alcanzado durante una prueba de esfuerzo.

Por qu√© importa: Un coraz√≥n sano suele alcanzar una buena frecuencia bajo esfuerzo.

# 9. Angina por ejercicio (exerciseAngina)
Tipo: 1 = S√≠, 0 = No

Qu√© es: Si el paciente experimenta dolor en el pecho al hacer ejercicio.

Por qu√© importa: Puede indicar flujo sangu√≠neo restringido al coraz√≥n.

# 10. Oldpeak (nivel de depresi√≥n ST)
Tipo: N√∫mero decimal (por ejemplo, 1.4)

Qu√© es: Diferencia entre el nivel ST en reposo y en esfuerzo (del ECG).

Por qu√© importa: Valores altos indican problemas en la respuesta del coraz√≥n al estr√©s.

# 11. ST Slope (pendiente del segmento ST)
Valores:

0 = Ascendente (Up)

1 = Plana (Flat)

2 = Descendente (Down)

Qu√© es: Forma de la curva ST en el electrocardiograma bajo esfuerzo.

Por qu√© importa: Cambios pueden indicar isquemia u otros problemas.

# Resultado final
Despu√©s de ingresar esos datos, el modelo devuelve:

"Positivo" ‚Üí Probablemente tiene enfermedad card√≠aca.

"Negativo" ‚Üí Probablemente no la tiene.

Esto permite usar el modelo como una herramienta de diagn√≥stico predictivo b√°sico.
